import random
import traceback
from langchain_google_vertexai import VertexAI
from langchain.output_parsers import StructuredOutputParser
from langchain.prompts import PromptTemplate
from langchain.schema import OutputParserException
from langchain.output_parsers import ResponseSchema
import pandas as pd
import json
import threading
from concurrent.futures import ThreadPoolExecutor

# ğŸ”¹ ConfiguraÃ§Ã£o do modelo VertexAI
model = VertexAI(model_name="gemini-2.0-flash")

# ğŸ”¹ Leitura do CSV e preparaÃ§Ã£o dos dados
arquivo_csv = "your-file"  # Substitua pelo caminho do seu arquivo de notÃ­cias
df = pd.read_csv(arquivo_csv)[:500]  # Ajuste a quantidade conforme necessÃ¡rio
docs = df.to_dict(orient="records")

# PreparaÃ§Ã£o dos documentos
lista = []
for row in docs:
    conteudo = f"""
    # Dados da NotÃ­cia
    TÃ­tulo: {row['title']}
    Data: {row['date']}
    Categoria: {row['category']}
    Subcategoria: {row['subcategory']}
    
    # ConteÃºdo da NotÃ­cia:
    {row['text']}
    """.strip()
    
    lista.append({
        "content": conteudo,
        "title": row['title'],
        "category": row['category'],
        "subcategory": row['subcategory']
    })

# ğŸ”¹ Schema de resposta para queries de notÃ­cias
response_schemas = [
    ResponseSchema(
        name="query_principal", 
        description="Pergunta especÃ­fica e prÃ¡tica baseada no conteÃºdo da notÃ­cia que um leitor interessado faria"
    ),
    ResponseSchema(
        name="resposta_consolidada", 
        description="Resposta clara e objetiva baseada no conteÃºdo da notÃ­cia"
    ),
    ResponseSchema(
        name="trecho_referencia", 
        description="Trecho especÃ­fico da notÃ­cia que fundamenta a resposta"
    ),
    ResponseSchema(
        name="categoria_tematica", 
        description="Tema principal da notÃ­cia (ex: PolÃ­tica, Economia, SaÃºde, Tecnologia, etc.)"
    ),
    ResponseSchema(
        name="palavras_chave", 
        description="Lista de 3-5 palavras-chave relevantes da notÃ­cia"
    )
]

parser = StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions = parser.get_format_instructions()

# ğŸ”¹ Prompt profissional para geraÃ§Ã£o de queries de notÃ­cias
prompt_template = PromptTemplate(
    template="""
VocÃª Ã© um especialista em anÃ¡lise de notÃ­cias e informaÃ§Ã£o jornalÃ­stica. Com base na notÃ­cia fornecida, 
gere uma pergunta realista que um leitor interessado no assunto faria sobre esta notÃ­cia.

DIRETRIZES IMPORTANTES:
1. A pergunta deve ser ESPECÃFICA e PRÃTICA
2. Deve refletir curiosidades genuÃ­nas que leitores teriam
3. Evite perguntas Ã³bvias que jÃ¡ estÃ£o claramente respondidas no tÃ­tulo
4. Foque nos aspectos mais relevantes e interessantes da notÃ­cia
5. Considere diferentes perspectivas (causas, consequÃªncias, contexto, detalhes)

TIPOS DE PERGUNTAS VÃLIDAS:
- ContextualizaÃ§Ã£o de eventos
- ConsequÃªncias ou impactos
- Causas ou motivaÃ§Ãµes
- Detalhes especÃ­ficos mencionados
- RelaÃ§Ãµes com outros eventos
- ImplicaÃ§Ãµes futuras
- Aspectos tÃ©cnicos explicados
- Dados e estatÃ­sticas mencionados

EVITE PERGUNTAS COMO:
- "Qual Ã© o tÃ­tulo da notÃ­cia?" (muito Ã³bvio)
- "Quando aconteceu?" (se estÃ¡ claro no texto)
- "O que aconteceu?" (muito genÃ©rico)

NOTÃCIA:
{noticia}

INSTRUÃ‡Ã•ES DE FORMATO:
{format_instructions}

Gere a query considerando que ela serÃ¡ usada para treinar um sistema 
de busca de notÃ­cias inteligente.
    """,
    input_variables=["noticia"],
    partial_variables={"format_instructions": format_instructions}
)

# ğŸ”¹ Controle de concorrÃªncia e buffer
lock = threading.Lock()
output_list = []
processed_count = 0

# ğŸ”¹ FunÃ§Ã£o para processar cada documento
def process_document(idx, documento):
    global processed_count
    
    try:
        # FormataÃ§Ã£o do prompt
        formatted_prompt = prompt_template.format(
            noticia=documento["content"]
        )
        
        # InvocaÃ§Ã£o do modelo
        response = model.invoke(formatted_prompt)
        
        # Parse da resposta
        parsed_output = parser.parse(response)
        parsed_output["documento_index"] = idx
        parsed_output["titulo_noticia"] = documento["title"]
        parsed_output["categoria_original"] = documento["category"]
        parsed_output["subcategoria_original"] = documento["subcategory"]
        
        # Thread-safe addition ao buffer
        with lock:
            output_list.append(parsed_output)
            processed_count += 1
            
        print(f"âœ” NotÃ­cia {idx + 1}/{len(lista)} processada. Query gerada.")
        
    except OutputParserException as e:
        print(f"âŒ Erro de parsing na notÃ­cia {idx}: {str(e)[:100]}...")
        # Tenta recuperar parcialmente
        try:
            with lock:
                output_list.append({
                    "documento_index": idx,
                    "titulo_noticia": documento["title"],
                    "erro": "Falha no parsing",
                    "resposta_bruta": str(response)[:500] if 'response' in locals() else "N/A"
                })
        except:
            pass
            
    except Exception as e:
        print(f"âŒ Erro geral na notÃ­cia {idx}: {str(e)}")

# ğŸ”¹ Processamento paralelo com controle de erro
print(f"ğŸš€ Iniciando processamento de {len(lista)} notÃ­cias...")

try:
    with ThreadPoolExecutor(max_workers=10) as executor:  # Reduzido para evitar rate limiting
        futures = [
            executor.submit(process_document, idx, documento) 
            for idx, documento in enumerate(lista)
        ]
        
        # Aguarda conclusÃ£o de todas as threads
        for future in futures:
            try:
                future.result(timeout=120)  # Timeout de 2 minutos por documento
            except Exception as e:
                print(f"âŒ Timeout ou erro na thread: {e}")

except Exception as e:
    print(f"âŒ Erro crÃ­tico no processamento paralelo: {e}")
    traceback.print_exc()

# ğŸ”¹ Salvamento dos resultados
output_filename = "queries_noticias.json"

try:
    with open(output_filename, "w", encoding="utf-8") as json_file:
        json.dump(output_list, json_file, ensure_ascii=False, indent=2)
    
    print(f"âœ… Processamento concluÃ­do!")
    print(f"ğŸ“Š Total processado: {processed_count}/{len(lista)} notÃ­cias")
    print(f"ğŸ’¾ Resultados salvos em: {output_filename}")
    
    # EstatÃ­sticas bÃ¡sicas
    if output_list:
        successful = len([item for item in output_list if "erro" not in item])
        print(f"ğŸ“ˆ Sucessos: {successful}, Erros: {len(output_list) - successful}")
        
        # EstatÃ­sticas por categoria
        categorias = {}
        for item in output_list:
            if "erro" not in item and "categoria_original" in item:
                cat = item["categoria_original"]
                categorias[cat] = categorias.get(cat, 0) + 1
        
        if categorias:
            print("\nğŸ“Š DistribuiÃ§Ã£o por categoria:")
            for cat, count in sorted(categorias.items(), key=lambda x: x[1], reverse=True):
                print(f"  {cat}: {count} notÃ­cias")
        
        # Amostra do resultado
        if successful > 0:
            print("\nğŸ” Exemplo de resultado gerado:")
            for item in output_list:
                if "erro" not in item:
                    print(f"TÃ­tulo: {item.get('titulo_noticia', 'N/A')[:60]}...")
                    print(f"Query: {item.get('query_principal', 'N/A')[:80]}...")
                    print(f"Categoria: {item.get('categoria_tematica', 'N/A')}")
                    break
    
except Exception as e:
    print(f"âŒ Erro ao salvar arquivo: {e}")
    # Backup em caso de erro
    try:
        with open("backup_queries_noticias.json", "w", encoding="utf-8") as backup_file:
            json.dump(output_list, backup_file, ensure_ascii=False)
        print("ğŸ’¾ Backup salvo como 'backup_queries_noticias.json'")
    except:
        print("âŒ Falha tambÃ©m no backup")

print("ğŸ ExecuÃ§Ã£o finalizada.")